{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‡»ğŸ‡³ GPT-SoVITS Vietnamese - Voice Cloning Pipeline\n",
    "\n",
    "Notebook tá»‘i Æ°u Ä‘á»ƒ clone giá»ng nÃ³i tiáº¿ng Viá»‡t trÃªn Google Colab.\n",
    "\n",
    "**Quy trÃ¬nh:** Upload Audio â†’ Cáº¯t + ASR â†’ Má»Ÿ WebUI (Train + Inference)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1ï¸âƒ£ CÃ i Ä‘áº·t mÃ´i trÆ°á»ng\n",
    "# @markdown Cháº¡y cell nÃ y Ä‘á»ƒ cÃ i Ä‘áº·t toÃ n bá»™ thÆ° viá»‡n cáº§n thiáº¿t.\n",
    "# @markdown â±ï¸ Thá»i gian: ~5-7 phÃºt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Clone repo (náº¿u chÆ°a cÃ³)\n",
    "if not os.path.exists(\"GPT-SoVITS\"):\n",
    "    print(\"ğŸ“¥ Äang táº£i GPT-SoVITS...\")\n",
    "    !git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n",
    "\n",
    "%cd GPT-SoVITS\n",
    "\n",
    "# CÃ i Ä‘áº·t dependencies\n",
    "print(\"ğŸ“¦ Äang cÃ i Ä‘áº·t thÆ° viá»‡n...\")\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q faster-whisper openai-whisper\n",
    "\n",
    "# Táº¡o thÆ° má»¥c pretrained models\n",
    "base_model_dir = \"GPT_SoVITS/pretrained_models\"\n",
    "os.makedirs(f\"{base_model_dir}/chinese-roberta-wwm-ext-large\", exist_ok=True)\n",
    "os.makedirs(f\"{base_model_dir}/chinese-hubert-base\", exist_ok=True)\n",
    "\n",
    "# Táº£i pretrained models\n",
    "print(\"ğŸ“¥ Äang táº£i pretrained models...\")\n",
    "!wget -nc -q -P {base_model_dir}/chinese-roberta-wwm-ext-large https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/config.json\n",
    "!wget -nc -q -P {base_model_dir}/chinese-roberta-wwm-ext-large https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/pytorch_model.bin\n",
    "!wget -nc -q -P {base_model_dir}/chinese-roberta-wwm-ext-large https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/tokenizer.json\n",
    "!wget -nc -q -P {base_model_dir}/chinese-hubert-base https://huggingface.co/TencentGameMate/chinese-hubert-base/resolve/main/config.json\n",
    "!wget -nc -q -P {base_model_dir}/chinese-hubert-base https://huggingface.co/TencentGameMate/chinese-hubert-base/resolve/main/pytorch_model.bin\n",
    "!wget -nc -q -P {base_model_dir}/chinese-hubert-base https://huggingface.co/TencentGameMate/chinese-hubert-base/resolve/main/preprocessor_config.json\n",
    "!wget -nc -q -P {base_model_dir} https://huggingface.co/lj1995/GPT-SoVITS/resolve/main/s2G488k.pth\n",
    "!wget -nc -q -P {base_model_dir} https://huggingface.co/lj1995/GPT-SoVITS/resolve/main/s2D488k.pth\n",
    "!wget -nc -q -P {base_model_dir} https://huggingface.co/lj1995/GPT-SoVITS/resolve/main/s1bert25Hz-2kh-longer-epoch=68e-step=50232.ckpt\n",
    "\n",
    "clear_output()\n",
    "print(\"âœ… CÃ i Ä‘áº·t hoÃ n táº¥t!\")\n",
    "print(\"ğŸ‘‰ Tiáº¿p tá»¥c cháº¡y Cell 2 Ä‘á»ƒ upload vÃ  xá»­ lÃ½ audio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2ï¸âƒ£ Upload Audio + Cáº¯t + ASR Tiáº¿ng Viá»‡t\n",
    "# @markdown Cháº¡y cell nÃ y Ä‘á»ƒ upload, cáº¯t audio vÃ  táº¡o phá»¥ Ä‘á» tiáº¿ng Viá»‡t.\n",
    "# @markdown â±ï¸ Thá»i gian: ~5-15 phÃºt (tÃ¹y Ä‘á»™ dÃ i audio)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# ========== Cáº¤U HÃŒNH ==========\n",
    "exp_name = \"MyVoice\" # @param {type:\"string\"}\n",
    "# ==============================\n",
    "\n",
    "# Táº¡o thÆ° má»¥c\n",
    "input_folder = f\"/content/dataset/{exp_name}\"\n",
    "sliced_folder = \"output/slicer_opt\"\n",
    "asr_output = f\"output/{exp_name}.list\"\n",
    "\n",
    "os.makedirs(input_folder, exist_ok=True)\n",
    "os.makedirs(sliced_folder, exist_ok=True)\n",
    "\n",
    "# Upload files\n",
    "print(\"ğŸ“¤ Vui lÃ²ng upload file audio (.mp3, .wav):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    shutil.move(filename, os.path.join(input_folder, filename))\n",
    "    print(f\"   âœ“ {filename}\")\n",
    "\n",
    "# ========== BÆ¯á»šC 1: Cáº®T AUDIO ==========\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ”ª BÆ¯á»šC 1: Cáº®T AUDIO THÃ€NH CÃC ÄOáº N NGáº®N\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "!python tools/slice_audio.py \"{input_folder}\" \"{sliced_folder}\" -34 4000 300 10 500 0.9 0.25 0 1\n",
    "\n",
    "sliced_files = [f for f in os.listdir(sliced_folder) if f.endswith(('.wav', '.mp3', '.flac'))]\n",
    "print(f\"\\nâœ… ÄÃ£ cáº¯t xong! Tá»•ng cá»™ng {len(sliced_files)} file audio.\")\n",
    "\n",
    "# ========== BÆ¯á»šC 2: ASR TIáº¾NG VIá»†T ==========\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ¤ BÆ¯á»šC 2: NHáº¬N Dáº NG GIá»ŒNG NÃ“I (ASR) TIáº¾NG VIá»†T\")\n",
    "print(\"=\"*50)\n",
    "print(\"â³ Äang cháº¡y Whisper large-v3... Vui lÃ²ng chá».\\n\")\n",
    "\n",
    "!python tools/asr/fasterwhisper_asr.py -i \"{sliced_folder}\" -o \"output\" -s large-v3 -l vi -p float16\n",
    "\n",
    "# TÃ¬m file .list Ä‘Æ°á»£c táº¡o\n",
    "list_files = [f for f in os.listdir(\"output\") if f.endswith('.list')]\n",
    "if list_files:\n",
    "    actual_list_file = f\"output/{list_files[0]}\"\n",
    "    # Rename to exp_name.list for clarity\n",
    "    if actual_list_file != asr_output:\n",
    "        shutil.copy(actual_list_file, asr_output)\n",
    "    \n",
    "    with open(asr_output, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"âœ… HOÃ€N Táº¤T!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"ğŸ“„ File .list: {os.path.abspath(asr_output)}\")\n",
    "    print(f\"ğŸ“ Tá»•ng sá»‘ dÃ²ng: {len(lines)}\")\n",
    "    print(f\"\\nğŸ“‹ 3 dÃ²ng Ä‘áº§u tiÃªn:\")\n",
    "    for i, line in enumerate(lines[:3]):\n",
    "        parts = line.strip().split('|')\n",
    "        if len(parts) >= 4:\n",
    "            print(f\"   {i+1}. [{parts[2]}] {parts[3][:50]}...\")\n",
    "else:\n",
    "    print(\"âŒ KhÃ´ng tÃ¬m tháº¥y file .list!\")\n",
    "\n",
    "print(\"\\nğŸ‘‰ Tiáº¿p tá»¥c cháº¡y Cell 3 Ä‘á»ƒ má»Ÿ WebUI.\")\n",
    "print(f\"ğŸ‘‰ Khi vÃ o WebUI, Ä‘iá»n Ä‘Æ°á»ng dáº«n nÃ y vÃ o Ã´ 'Text Label File':\")\n",
    "print(f\"   {os.path.abspath(asr_output)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3ï¸âƒ£ Khá»Ÿi Ä‘á»™ng WebUI (Training + Inference)\n",
    "# @markdown **Cell nÃ y cháº¡y liÃªn tá»¥c.** Má»Ÿ link gradio.live Ä‘á»ƒ lÃ m viá»‡c.\n",
    "# @markdown\n",
    "# @markdown **TrÃªn WebUI:**\n",
    "# @markdown - Tab 1A: Paste Ä‘Æ°á»ng dáº«n .list â†’ Format data\n",
    "# @markdown - Tab 1B: Train SoVITS â†’ Train GPT\n",
    "# @markdown - Tab 1C: Chá»n model â†’ Inference\n",
    "\n",
    "import os\n",
    "\n",
    "# Cáº¥u hÃ¬nh paths\n",
    "cwd = os.getcwd()\n",
    "bert_path = os.path.join(cwd, \"GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\")\n",
    "hubert_path = os.path.join(cwd, \"GPT_SoVITS/pretrained_models/chinese-hubert-base\")\n",
    "\n",
    "os.environ[\"cnhubert_base_path\"] = hubert_path\n",
    "os.environ[\"bert_path\"] = bert_path\n",
    "os.environ[\"is_share\"] = \"True\"\n",
    "\n",
    "print(\"ğŸš€ Äang khá»Ÿi Ä‘á»™ng WebUI...\")\n",
    "print(\"â³ Chá» 1-2 phÃºt Ä‘á»ƒ load xong.\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“‹ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG WEBUI:\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. Tab 1 â†’ 1A: Äiá»n tÃªn experiment vÃ  Ä‘Æ°á»ng dáº«n file .list\")\n",
    "print(\"2. Báº¥m nÃºt 'One-click format'\")\n",
    "print(\"3. Tab 1 â†’ 1B: Train SoVITS (epochs=8), sau Ä‘Ã³ Train GPT (epochs=15)\")\n",
    "print(\"4. Tab 1 â†’ 1C: Chá»n model â†’ Inference\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "!sed -i 's/is_share = False/is_share = True/g' config.py 2>/dev/null || true\n",
    "!python webui.py --share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4ï¸âƒ£ LÆ°u Model vá» Google Drive (TÃ¹y chá»n)\n",
    "# @markdown Cháº¡y cell nÃ y SAU KHI train xong Ä‘á»ƒ backup model.\n",
    "\n",
    "from google.colab import drive\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "exp_name = \"MyVoice\" # @param {type:\"string\"}\n",
    "drive_path = f\"/content/drive/MyDrive/GPT_SoVITS_Models/{exp_name}\"\n",
    "\n",
    "# Mount Drive\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“¦ Äang lÆ°u model {exp_name} vÃ o Drive...\")\n",
    "\n",
    "# Copy trained models\n",
    "!cp -r logs/{exp_name}/* \"{drive_path}/\" 2>/dev/null || true\n",
    "!cp GPT_SoVITS/weights/*.pth \"{drive_path}/\" 2>/dev/null || true\n",
    "!cp GPT_SoVITS/weights/*.ckpt \"{drive_path}/\" 2>/dev/null || true\n",
    "\n",
    "print(f\"\\nâœ… ÄÃ£ lÆ°u xong táº¡i: {drive_path}\")\n",
    "print(\"ğŸ“‚ CÃ¡c file Ä‘Ã£ lÆ°u:\")\n",
    "!ls -la \"{drive_path}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
