{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_md",
   "metadata": {},
   "source": [
    "# GPT-SoVITS v2 - Vietnamese Voice Cloning Pipeline (Optimized)\n",
    "\n",
    "Notebook nÃ y Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘á»ƒ linh hoáº¡t vÃ  dá»… sá»­ dá»¥ng hÆ¡n.\n",
    "\n",
    "### ðŸš€ Quy trÃ¬nh thá»±c hiá»‡n:\n",
    "1. **CÃ i Ä‘áº·t mÃ´i trÆ°á»ng**: Cháº¡y 1 láº§n Ä‘áº§u tiÃªn.\n",
    "2. **Cáº¥u hÃ¬nh chung**: Äáº·t tÃªn model (Experiment Name) táº¡i Ä‘Ã¢y.\n",
    "3. **Táº£i Dá»¯ liá»‡u**: Upload file Ã¢m thanh tá»« mÃ¡y hoáº·c Drive.\n",
    "4. **Xá»­ lÃ½ Dá»¯ liá»‡u**: Cáº¯t Ã¢m thanh vÃ  táº¡o phá»¥ Ä‘á» (ASR).\n",
    "5. **WebUI**: Má»Ÿ giao diá»‡n Ä‘á»ƒ Train vÃ  Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1_install",
   "metadata": {
    "id": "step1_install"
   },
   "outputs": [],
   "source": [
    "# @title 1. CÃ i Ä‘áº·t MÃ´i trÆ°á»ng, UVR5 & GPT-SoVITS (Fix Download)\n",
    "# @markdown Cháº¡y cell nÃ y Ä‘á»ƒ cÃ i Ä‘áº·t toÃ n bá»™ thÆ° viá»‡n vÃ  táº£i model thá»§ cÃ´ng.\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Drive Ä‘á»ƒ dÃ¹ng Smart Cache (tá»± Ä‘á»™ng lÆ°u/táº£i model)\n",
    "if not os.path.exists('/content/drive'):\n",
    "    try:\n",
    "        drive.mount('/content/drive')\n",
    "    except: \n",
    "        print('Skipping Drive mount (manual or local runtime)')\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# 1. Clone Repo GPT-SoVITS\n",
    "if not os.path.exists(\"GPT-SoVITS-Vietnamese\"):\n",
    "    print(\"Dang clone repository GPT-SoVITS...\")\n",
    "    !git clone https://github.com/tqtuan8788-ai/GPT-SoVITS-Vietnamese.git\n",
    "    %cd GPT-SoVITS-Vietnamese\n",
    "else:\n",
    "    %cd GPT-SoVITS-Vietnamese\n",
    "    !git pull\n",
    "\n",
    "# 2. Install Dependencies\n",
    "print(\"Dang cai dat thu vien chinh...\")\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q openai-whisper\n",
    "\n",
    "# 3. CÃ i Ä‘áº·t UVR5 (Ä‘á»ƒ tÃ¡ch nháº¡c/vocal)\n",
    "print(\"Dang cai dat UVR5 va cac cong cu xu ly am thanh...\")\n",
    "!pip install -q soundfile librosa noise-reduction onnxruntime-gpu\n",
    "# Táº£i model UVR5\n",
    "!mkdir -p uvr5_weights\n",
    "!wget -nc -P uvr5_weights https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP5_only_main_vocal.pth\n",
    "!wget -nc -P uvr5_weights https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/onnx_dereverb_By_FoxJoy/vocals.onnx\n",
    "\n",
    "# 4. Táº£i Pretrained Models THá»¦ CÃ”NG (Fix lá»—i script download)\n",
    "print(\"Dang tai pre-trained models thu cong tu Hugging Face...\")\n",
    "\n",
    "# Táº¡o Ä‘Ãºng cáº¥u trÃºc thÆ° má»¥c mÃ  code yÃªu cáº§u: GPT_SoVITS/pretrained_models/...\n",
    "base_model_dir = \"GPT_SoVITS/pretrained_models\"\n",
    "os.makedirs(base_model_dir, exist_ok=True)\n",
    "os.makedirs(f\"{base_model_dir}/chinese-roberta-wwm-ext-large\", exist_ok=True)\n",
    "os.makedirs(f\"{base_model_dir}/chinese-hubert-base\", exist_ok=True)\n",
    "\n",
    "# Táº£i Chinese-Roberta (Báº¯t buá»™c cho Text encoding)\n",
    "!wget -nc -P {base_model_dir}/chinese-roberta-wwm-ext-large https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/config.json\n",
    "!wget -nc -P {base_model_dir}/chinese-roberta-wwm-ext-large https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/pytorch_model.bin\n",
    "!wget -nc -P {base_model_dir}/chinese-roberta-wwm-ext-large https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/tokenizer.json\n",
    "\n",
    "# Táº£i Chinese-Hubert (Báº¯t buá»™c cho Audio encoding)\n",
    "!wget -nc -P {base_model_dir}/chinese-hubert-base https://huggingface.co/TencentGameMate/chinese-hubert-base/resolve/main/config.json\n",
    "!wget -nc -P {base_model_dir}/chinese-hubert-base https://huggingface.co/TencentGameMate/chinese-hubert-base/resolve/main/pytorch_model.bin\n",
    "!wget -nc -P {base_model_dir}/chinese-hubert-base https://huggingface.co/TencentGameMate/chinese-hubert-base/resolve/main/preprocessor_config.json\n",
    "\n",
    "# Táº£i GPT-SoVITS v2 Pretrained Models (s2G, s2D, s1bert)\n",
    "!wget -nc -P {base_model_dir} https://huggingface.co/lj1995/GPT-SoVITS/resolve/main/s2G488k.pth\n",
    "!wget -nc -P {base_model_dir} https://huggingface.co/lj1995/GPT-SoVITS/resolve/main/s2D488k.pth\n",
    "!wget -nc -P {base_model_dir} https://huggingface.co/lj1995/GPT-SoVITS/resolve/main/s1bert25Hz-2kh-longer-epoch=68e-step=50232.ckpt\n",
    "\n",
    "# Táº£i G2PW Model (Cho tiáº¿ng Trung, nhÆ°ng script váº«n check)\n",
    "!wget -nc -P GPT_SoVITS/text/G2PWModel https://paddlespeech.bj.bcebos.com/Parakeet/op_g2p_model/G2PWModel/G2PWModel_1.1.zip\n",
    "!unzip -o -q GPT_SoVITS/text/G2PWModel/G2PWModel_1.1.zip -d GPT_SoVITS/text/G2PWModel\n",
    "\n",
    "clear_output()\n",
    "print(\"âœ… CÃ i Ä‘áº·t hoÃ n táº¥t! ÄÃ£ táº£i Ä‘á»§ models thá»§ cÃ´ng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1_5_config",
   "metadata": {
    "id": "step1_5_config"
   },
   "outputs": [],
   "source": [
    "# @title âš™ï¸ 2. Cáº¥u hÃ¬nh Chung (QUAN TRá»ŒNG)\n",
    "# @markdown Nháº­p tÃªn experiment cá»§a báº¡n á»Ÿ Ä‘Ã¢y. TÃªn nÃ y sáº½ Ä‘Æ°á»£c dÃ¹ng xuyÃªn suá»‘t notebook.\n",
    "exp_name = \"Giong_Doc_Sach_01\" # @param {type:\"string\"}\n",
    "\n",
    "# @markdown TÃ­ch chá»n náº¿u muá»‘n táº£i láº¡i model cÅ© tá»« Drive Ä‘á»ƒ train tiáº¿p (Resume Training)\n",
    "resume_from_drive = False # @param {type:\"boolean\"}\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "# Common paths\n",
    "drive_root = \"/content/drive/MyDrive/GPT_SoVITS_Models\"\n",
    "dataset_root = \"/content/dataset\"\n",
    "output_root = \"/content/GPT-SoVITS-Vietnamese/output\"\n",
    "\n",
    "# Mount Drive check\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "print(f\"âœ… ÄÃ£ cáº¥u hÃ¬nh: {exp_name}\")\n",
    "\n",
    "# Logic Resume\n",
    "if resume_from_drive:\n",
    "    drive_exp_path = os.path.join(drive_root, exp_name)\n",
    "    if os.path.exists(drive_exp_path):\n",
    "        print(f\"ðŸ”„ TÃ¬m tháº¥y model cÅ© trong Drive. Äang khÃ´i phá»¥c...\")\n",
    "        # Restore weights\n",
    "        !cp -r \"{drive_exp_path}\"/*.pth GPT_SoVITS/weights/ 2>/dev/null || true\n",
    "        !cp -r \"{drive_exp_path}\"/*.ckpt GPT_SoVITS/weights/ 2>/dev/null || true\n",
    "        # Restore logs (checkpoints)\n",
    "        !mkdir -p logs/{exp_name}\n",
    "        !cp -r \"{drive_exp_path}\"/* logs/{exp_name}/ 2>/dev/null || true\n",
    "        print(\"âœ… ÄÃ£ khÃ´i phá»¥c model thÃ nh cÃ´ng!\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y folder {exp_name} trong Drive ({drive_root}). Bá» qua bÆ°á»›c resume.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step2_data_upload",
   "metadata": {
    "id": "step2_data_upload"
   },
   "outputs": [],
   "source": [
    "# @title 3. Táº£i Dá»¯ liá»‡u Audio\n",
    "# @markdown Chá»n nguá»“n dá»¯ liá»‡u vÃ  upload file. Tá»± Ä‘á»™ng dÃ¹ng `exp_name` Ä‘Ã£ cáº¥u hÃ¬nh á»Ÿ trÃªn.\n",
    "\n",
    "import os\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Use global exp_name\n",
    "if 'exp_name' not in globals():\n",
    "    exp_name = \"Giong_Doc_Sach_01\" # Fallback\n",
    "    print(\"âš ï¸ Warning: exp_name chÆ°a Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a. DÃ¹ng máº·c Ä‘á»‹nh.\")\n",
    "\n",
    "source_type = \"Direct Upload\" # @param [\"Direct Upload\", \"Google Drive\"]\n",
    "google_drive_path = \"/content/drive/MyDrive/my_audio_folder\" # @param {type:\"string\"}\n",
    "\n",
    "input_audio_folder = f\"{dataset_root}/{exp_name}\"\n",
    "os.makedirs(input_audio_folder, exist_ok=True)\n",
    "\n",
    "if source_type == \"Google Drive\":\n",
    "    if os.path.exists(google_drive_path):\n",
    "        print(f\"Dang copy tu {google_drive_path}...\")\n",
    "        for f in os.listdir(google_drive_path):\n",
    "            if f.endswith((\".wav\", \".mp3\", \".flac\")):\n",
    "                shutil.copy(os.path.join(google_drive_path, f), input_audio_folder)\n",
    "        print(\"âœ… Da copy xong!\")\n",
    "    else:\n",
    "        print(\"âŒ Khong tim thay thu muc Google Drive!\")\n",
    "\n",
    "else:\n",
    "    print(\"ðŸ“‚ Vui lÃ²ng chá»n file audio (.wav, .mp3) Ä‘á»ƒ upload:\")\n",
    "    uploaded = files.upload()\n",
    "    for filename in uploaded.keys():\n",
    "        shutil.move(filename, os.path.join(input_audio_folder, filename))\n",
    "    print(\"âœ… Upload hoÃ n táº¥t!\")\n",
    "\n",
    "# Kiá»ƒm tra káº¿t quáº£\n",
    "if os.path.exists(input_audio_folder):\n",
    "    files = os.listdir(input_audio_folder)\n",
    "    print(f\"\\nðŸ“ ThÆ° má»¥c dataset: {input_audio_folder}\")\n",
    "    print(f\"ðŸŽµ Sá»‘ lÆ°á»£ng file: {len(files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step3_slice_asr",
   "metadata": {
    "id": "step3_slice_asr"
   },
   "outputs": [],
   "source": [
    "# @title 4. Cáº¯t Audio + Táº¡o Phá»¥ Äá» Tiáº¿ng Viá»‡t (ASR)\n",
    "# @markdown Tá»± Ä‘á»™ng cáº¯t vÃ  táº¡o file list dá»±a trÃªn `exp_name`.\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Äáº£m báº£o Ä‘ang á»Ÿ Ä‘Ãºng thÆ° má»¥c repo\n",
    "%cd /content/GPT-SoVITS-Vietnamese\n",
    "\n",
    "# --- FIX Lá»–I FFMPEG (Quan trá»ng) ---\n",
    "print(\"ðŸ› ï¸ Äang vÃ¡ lá»—i Ä‘Æ°á»ng dáº«n FFMPEG...\")\n",
    "# Thay tháº¿ Ä‘Æ°á»ng dáº«n Windows cá»©ng báº±ng 'ffmpeg' chuáº©n cá»§a Linux\n",
    "!sed -i 's|cmd=\\[r\"C:.*ffmpeg-win-x86_64-v7.1.exe\", \"-nostdin\"\\]|cmd=[\"ffmpeg\", \"-nostdin\"]|g' tools/my_utils.py\n",
    "\n",
    "# CÃ i Ä‘áº·t thÃªm dependencies cáº§n thiáº¿t\n",
    "!pip install -q faster-whisper\n",
    "\n",
    "# Set PYTHONPATH\n",
    "import sys\n",
    "sys.path.insert(0, '/content/GPT-SoVITS-Vietnamese')\n",
    "os.environ['PYTHONPATH'] = '/content/GPT-SoVITS-Vietnamese'\n",
    "\n",
    "# Use global exp_name\n",
    "if 'exp_name' not in globals():\n",
    "    exp_name = \"Giong_Doc_Sach_01\"\n",
    "\n",
    "input_audio_folder = f\"/content/dataset/{exp_name}\"\n",
    "sliced_output_folder = \"output/slicer_opt\"\n",
    "asr_output_file = f\"output/{exp_name}.list\"\n",
    "\n",
    "os.makedirs(sliced_output_folder, exist_ok=True)\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# ========== BÆ¯á»šC 1: Cáº®T AUDIO ==========\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ”ª BÆ¯á»šC 1: Cáº®T AUDIO THÃ€NH CÃC ÄOáº N NGáº®N\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# CHECK INPUT DATA (New debug step)\n",
    "if not os.path.exists(input_audio_folder):\n",
    "    print(f\"âŒ Lá»–I: ThÆ° má»¥c input khÃ´ng tá»“n táº¡i: {input_audio_folder}\")\n",
    "    print(\"ðŸ‘‰ Vui lÃ²ng cháº¡y láº¡i Step 3 Ä‘á»ƒ upload audio!\")\n",
    "    raise FileNotFoundError(\"Input folder missing\")\n",
    "\n",
    "files_in_input = os.listdir(input_audio_folder)\n",
    "print(f\"ðŸ“‚ Input folder: {input_audio_folder}\")\n",
    "print(f\"ðŸ” TÃ¬m tháº¥y {len(files_in_input)} file.\")\n",
    "if len(files_in_input) == 0:\n",
    "    print(\"âŒ Lá»–I: ThÆ° má»¥c input rá»—ng! ChÆ°a cÃ³ file audio nÃ o.\")\n",
    "    raise ValueError(\"Input folder is empty\")\n",
    "else:\n",
    "    print(f\"   - File máº«u: {files_in_input[:3]}\")\n",
    "\n",
    "# Clean output folder before slicing to avoid mixing old data\n",
    "!rm -rf {sliced_output_folder}/*\n",
    "\n",
    "# Cháº¡y slice audio\n",
    "slice_cmd = f'python tools/slice_audio.py \"{input_audio_folder}\" \"{sliced_output_folder}\" -34 4000 300 10 500 0.9 0.25 0 1'\n",
    "print(f\"Running: {slice_cmd}\")\n",
    "os.system(slice_cmd)\n",
    "\n",
    "if os.path.exists(sliced_output_folder):\n",
    "    sliced_files = [f for f in os.listdir(sliced_output_folder) if f.endswith((\".wav\", \".mp3\", \".flac\"))]\n",
    "    if len(sliced_files) == 0:\n",
    "        print(\"\\nâŒ Lá»–I NGHIÃŠM TRá»ŒNG: QuÃ¡ trÃ¬nh cáº¯t audio khÃ´ng táº¡o ra file nÃ o!\")\n",
    "        print(\"ðŸ‘‰ NguyÃªn nhÃ¢n cÃ³ thá»ƒ: File input quÃ¡ ngáº¯n, bá»‹ lá»—i format, hoáº·c tham sá»‘ cáº¯t quÃ¡ gáº¯t.\")\n",
    "        print(\"ðŸ‘‰ Vui lÃ²ng kiá»ƒm tra láº¡i thÆ° má»¥c input hoáº·c file audio gá»‘c.\")\n",
    "        raise RuntimeError(\"Slicing failed - No output files\")\n",
    "    print(f\"\\nâœ… ÄÃ£ cáº¯t xong! Tá»•ng cá»™ng {len(sliced_files)} file audio.\\n\")\n",
    "else:\n",
    "    print(\"\\nâŒ Lá»–I: ThÆ° má»¥c output chÆ°a Ä‘Æ°á»£c táº¡o.\\n\")\n",
    "    raise RuntimeError(\"Slicing output folder missing\")\n",
    "\n",
    "# ========== BÆ¯á»šC 2: ASR TIáº¾NG VIá»†T ==========\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸŽ¤ BÆ¯á»šC 2: NHáº¬N Dáº NG GIá»ŒNG NÃ“I (ASR) TIáº¾NG VIá»†T\")\n",
    "print(\"=\"*60)\n",
    "print(\"â³ Äang cháº¡y Whisper large-v3... Vui lÃ²ng chá» 2-10 phÃºt.\\n\")\n",
    "\n",
    "# Cháº¡y ASR\n",
    "asr_cmd = f'python tools/asr/fasterwhisper_asr.py -i \"{sliced_output_folder}\" -o \"output\" -s large-v3 -l vi -p float32'\n",
    "print(f\"Running: {asr_cmd}\")\n",
    "os.system(asr_cmd)\n",
    "\n",
    "# Rename generated file to match exp_name\n",
    "generated_asr_file = \"output/slicer_opt.list\"\n",
    "if os.path.exists(generated_asr_file):\n",
    "    if os.path.exists(asr_output_file):\n",
    "        os.remove(asr_output_file)\n",
    "    os.rename(generated_asr_file, asr_output_file)\n",
    "\n",
    "# Kiá»ƒm tra file .list\n",
    "if os.path.exists(asr_output_file):\n",
    "    with open(asr_output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    print(f\"\\nâœ… ÄÃƒ Táº O FILE .LIST THÃ€NH CÃ”NG!\")\n",
    "    print(f\"ðŸ“„ ÄÆ°á»ng dáº«n: {os.path.abspath(asr_output_file)}\")\n",
    "    print(f\"ðŸ“ Tá»•ng sá»‘ dÃ²ng: {len(lines)}\")\n",
    "else:\n",
    "    print(\"âŒ Lá»–I: KhÃ´ng táº¡o Ä‘Æ°á»£c file .list!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… HOÃ€N Táº¤T! Tiáº¿p tá»¥c cháº¡y Cell 5 Ä‘á»ƒ má»Ÿ WebUI.\")\n",
    "print(f\"ðŸ‘‰ Khi vÃ o WebUI, Ä‘iá»n Ä‘Æ°á»ng dáº«n nÃ y vÃ o Ã´ Text Label File: {os.path.abspath(asr_output_file)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step4_webui",
   "metadata": {
    "id": "step4_webui"
   },
   "outputs": [],
   "source": [
    "# @title 5. Khá»Ÿi Ä‘á»™ng WebUI\n",
    "# @markdown **Cell nÃ y sáº½ cháº¡y liÃªn tá»¥c.** LÃ m viá»‡c trÃªn link Gradio hiá»‡n ra.\n",
    "\n",
    "import os\n",
    "\n",
    "%cd /content/GPT-SoVITS-Vietnamese\n",
    "\n",
    "# Patch config paths\n",
    "cwd = os.getcwd()\n",
    "possible_bert_paths = [\n",
    "    os.path.join(cwd, \"GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\"),\n",
    "    os.path.join(cwd, \"pretrained_models/chinese-roberta-wwm-ext-large\"),\n",
    "    \"/content/GPT-SoVITS/GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\"\n",
    "]\n",
    "found_bert = next((p for p in possible_bert_paths if os.path.exists(p)), possible_bert_paths[0])\n",
    "found_hubert = found_bert.replace(\"chinese-roberta-wwm-ext-large\", \"chinese-hubert-base\")\n",
    "\n",
    "os.environ[\"cnhubert_base_path\"] = found_hubert\n",
    "os.environ[\"bert_path\"] = found_bert\n",
    "os.environ[\"colab_active\"] = \"1\"\n",
    "os.environ[\"is_share\"] = \"True\"\n",
    "\n",
    "print(\"ðŸš€ Äang khá»Ÿi Ä‘á»™ng WebUI...\")\n",
    "print(\"ðŸ“‹ HÆ¯á»šNG DáºªN:\")\n",
    "print(\"1. Tab 1 -> 1A: Äiá»n tÃªn experiment vÃ  Ä‘Æ°á»ng dáº«n file .list (Ä‘Ã£ hiá»‡n á»Ÿ bÆ°á»›c trÃªn)\")\n",
    "print(\"2. Báº¥m Format data\")\n",
    "print(\"3. Tab 1 -> 1B: Train SoVITS & Train GPT\")\n",
    "print(\"4. Tab 1 -> 1C: Chá»n model vÃ  Inference\")\n",
    "\n",
    "!sed -i \"s/is_share = False/is_share = True/g\" config.py\n",
    "!python webui.py --share --i18n_dir ./i18n/vi_VN.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step3_5_asr_manual",
   "metadata": {
    "id": "step3_5_asr_manual"
   },
   "outputs": [],
   "source": [
    "# @title (TÃ¹y chá»n) Cháº¡y láº¡i ASR thá»§ cÃ´ng\n",
    "# @markdown Chá»‰ cháº¡y cell nÃ y náº¿u báº¡n muá»‘n cháº¡y láº¡i bÆ°á»›c táº¡o phá»¥ Ä‘á» cho file audio Ä‘Ã£ cáº¯t.\n",
    "\n",
    "import os\n",
    "if 'exp_name' not in globals():\n",
    "    exp_name = \"Giong_Doc_Sach_01\"\n",
    "\n",
    "sliced_audio_folder = \"output/slicer_opt\"\n",
    "output_list_file = f\"output/{exp_name}.list\"\n",
    "\n",
    "if not os.path.exists(sliced_audio_folder):\n",
    "    print(\"âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c Ä‘Ã£ cáº¯t!\")\n",
    "else:\n",
    "    print(\"ðŸš€ Äang cháº¡y Whisper (large-v3)...\")\n",
    "    !python tools/asr/fasterwhisper_asr.py -i \"{sliced_audio_folder}\" -o \"output\" -s large-v3 -l vi -p float32\n",
    "    \n",
    "    # Rename\n",
    "    generated = \"output/slicer_opt.list\"\n",
    "    if os.path.exists(generated):\n",
    "        import shutil\n",
    "        shutil.move(generated, output_list_file)\n",
    "    \n",
    "    print(f\"âœ… ÄÃ£ xong: {os.path.abspath(output_list_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step4_save_model",
   "metadata": {
    "id": "step4_save_model"
   },
   "outputs": [],
   "source": [
    "# @title 6. LÆ°u Model vá» Drive\n",
    "save_to_drive = True # @param {type:\"boolean\"}\n",
    "\n",
    "if 'exp_name' not in globals():\n",
    "    exp_name = \"Giong_Doc_Sach_01\"\n",
    "\n",
    "drive_save_path = f\"/content/drive/MyDrive/GPT_SoVITS_Models/{exp_name}\"\n",
    "\n",
    "if save_to_drive:\n",
    "    from google.colab import drive\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        drive.mount('/content/drive')\n",
    "    \n",
    "    os.makedirs(drive_save_path, exist_ok=True)\n",
    "    print(f\"Dang luu model {exp_name} vao Drive...\")\n",
    "\n",
    "    !cp GPT_SoVITS/pretrained_models/s2G*.pth \"{drive_save_path}\"/\n",
    "    !cp GPT_SoVITS/pretrained_models/s1bert*.ckpt \"{drive_save_path}\"/\n",
    "    !cp -r GPT_SoVITS/weights/* \"{drive_save_path}\"/ 2>/dev/null || true\n",
    "    !cp -r logs/{exp_name}/* \"{drive_save_path}\"/ 2>/dev/null || true\n",
    "    \n",
    "    print(f\"âœ… Da luu xong tai: {drive_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
